## content imported from KAGGLE website Kernels
## import packages
import csv
import pandas as pd
from pandas import DataFrame
import numpy as np
from numpy.random import randn
import tensorflow as tf
from numpy import arange,array,ones
import tensorflow_hub as hub
import os

os.environ["TFHUB_CACHE_DIR"] = str(os.getcwd() + '/tfhub')

## preprocessing data
with open('train.csv', 'r') as csvfile:
    trainCSV = csv.reader(csvfile, delimiter = ',')
    
train_raw = pd.read_csv("train.csv", error_bad_lines=False, header = None, delimiter = ',')

train_op = train_raw
train_op.head()

train_text = train_op[[2]]
train_text = train_text.drop([0])
train_text_list = train_text.values.tolist()
text_array = []
for i in train_text_list:
    j = str(i)
    j = j[2:len(j)-2]
    text_array.append(j)
    
train_target = train_op[[1]]
train_target = train_target.drop([0])
list1 = train_target.values.tolist()
type(list1)
target_array = np.reshape(list1, (len(list1),))
#for item in list1:
 #   string = item[2:len(item)-2]
target_array = target_array.astype(np.float)


sample_outputt = target_array[0:1000]

## TRAIN THE MODEL WITH DATA
x = tf.placeholder(dtype=tf.string, shape=[None])
embed = hub.Module("https://tfhub.dev/google/universal-sentence-encoder-large/3")
embeddings = embed(x)


with tf.Session() as sess:
    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])
    output = sess.run(embeddings, feed_dict = {
        x: ["I hate brocolli.", "Avengers Endgame is an overrated movie."]
    })
print(output)

sample_text = text_array[0:1000]
sample_target = target_array[0:1000]

# forward
hidden = tf.layers.dense(inputs = embeddings, units = 1024, activation = tf.nn.relu)

output = tf.layers.dense(inputs = hidden, units = 1, activation = tf.nn.sigmoid)

# backforward
y = tf.placeholder(dtype=tf.float32, shape=[None])
output1 = tf.reshape(output, [100,])

cost = tf.losses.mean_squared_error(y, output1) 
optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)

with tf.Session() as sess:
    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])  
    
    for i in range(0,5):
        for j in range (0, 10):
            
            loss, last = sess.run([cost, optimizer], feed_dict = {
                 x: sample_text[j*100: 100*(j+1)],
                 y: sample_target[j*100: 100*(j+1)]
            })
        print (loss)
        
 


    
